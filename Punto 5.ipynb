{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Nota:**\n",
        "\n",
        "Este script solo me funciono en google colab ya que me generaba error con el dataset que descargaba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c9rAH8usRTAj"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MxsuFnbIRW2g"
      },
      "outputs": [],
      "source": [
        "# Load the MNIST dataset\n",
        "mnist = fetch_openml('mnist_784', version=1)\n",
        "X, y = mnist['data'], mnist['target'].astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WOFbJ6SvRW33"
      },
      "outputs": [],
      "source": [
        "# Filter the dataset for digits 0 through 8\n",
        "filter_mask = (y >= 0) & (y <= 8)  # Use '&' for element-wise AND\n",
        "X_filtered = X[filter_mask]\n",
        "y_filtered = y[filter_mask]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ggPMytYtRW6i"
      },
      "outputs": [],
      "source": [
        "# Display class counts\n",
        "class_counts = np.bincount(y_filtered)\n",
        "print(f'Class Counts: {class_counts}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mG7HRTPHRW9A"
      },
      "outputs": [],
      "source": [
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_filtered, y_filtered, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iOoBEa3QRW_O"
      },
      "outputs": [],
      "source": [
        "# Create and train the logistic regression model\n",
        "model = LogisticRegression(max_iter=500, random_state=42, class_weight='balanced')\n",
        "model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YzdnAHe-RiY9"
      },
      "outputs": [],
      "source": [
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I2Mb9nCgRicT"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model's performance\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "classification_rep = classification_report(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GDTavMssRmnp"
      },
      "outputs": [],
      "source": [
        "# Print the results\n",
        "print(f'Accuracy: {accuracy:.2f}')\n",
        "print('Confusion Matrix:')\n",
        "print(conf_matrix)\n",
        "print('Classification Report:')\n",
        "print(classification_rep)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-MLXwCLGTT6q"
      },
      "source": [
        "**Accuracy:**\n",
        "\n",
        "**Accuracy: 0,92**\n",
        "\n",
        "La precisión global del modelo es del 92%, lo que indica que clasificó correctamente los dígitos aproximadamente el 92% de las veces.\n",
        "\n",
        "**Matriz de confusión:**\n",
        "\n",
        "* Cada fila de la matriz de confusión corresponde a la clase verdadera, y cada columna corresponde a la clase predicha.\n",
        "* ***Ejemplo:*** El elemento de la primera fila y de la segunda columna (índice 0) es el número de casos en los que la clase verdadera es 0 pero el modelo predijo 1.\n",
        "Interpretación: La matriz de confusión muestra el rendimiento del modelo para cada dígito.\n",
        "\n",
        "**Precisión, recuperación, puntuación F1:**\n",
        "\n",
        "* Precisión: La precisión es el número de verdaderos positivos dividido por la suma de verdaderos positivos y falsos positivos. Mide la exactitud de las predicciones positivas.\n",
        "* Recall (Sensibilidad): La recuperación es el número de verdaderos positivos dividido por la suma de verdaderos positivos y falsos negativos. Mide la capacidad del modelo para capturar todos los casos positivos.\n",
        "* Puntuación F1: La puntuación F1 es la media armónica de la precisión y la recuperación. Proporciona un equilibrio entre precisión y recuperación.\n",
        "\n",
        "**Interpretación:**\n",
        "\n",
        "* Precisión: Proporción de identificaciones positivas (predicciones) que fueron realmente correctas.\n",
        "Recuperación: La proporción de positivos reales que fueron identificados correctamente por el modelo.\n",
        "Puntuación F1: El equilibrio entre precisión y recuperación.\n",
        "\n",
        "**Support:**\n",
        "\n",
        "Número de casos reales de la clase en el conjunto de datos especificado.\n",
        "\n",
        "**Resumen:**\n",
        "\n",
        "* El informe de clasificación ofrece un desglose detallado de la precisión, la recuperación y la puntuación F1 de cada clase (dígito), junto con las medias macro y ponderadas.\n",
        "* El modelo parece funcionar bien en la mayoría de los dígitos, con valores altos de precisión, recuperación y puntuación F1.\n",
        "* Tenga en cuenta que la interpretación puede variar en función de los requisitos específicos de su aplicación."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
